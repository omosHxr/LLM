{
  "dim": 768,
  "heads": 12,
  "layers": 12,
  "seq_length": 512,
  "vocab_size": 32768,
  "ff_dim": 3072,
  "dropout": 0.1,
  "activation": "gelu",
  "norm_eps": 1e-05
}